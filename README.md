# Проект автодополнения текста с LSTM и трансформерными моделями

## Обзор
Этот проект реализует систему автодополнения текста с использованием обучаемой модели LSTM и предобученной трансформерной модели distilgpt2. Проект обрабатывает русскоязычные тексты, обучает LSTM предсказывать следующий токен в последовательностях и оценивает качество моделей с помощью метрик ROUGE. Трансформер используется в качестве сильного базиса для сравнения.

## Основные возможности
- Очистка и токенизация текста с помощью токенизатора RuBERT от DeepPavlov.
- Подготовка датасета: создание пар токенов для задачи предсказания следующего токена.
- Разбиение датасета на обучающую, валидационную и тестовую выборки в пропорциях 80/10/10.
- Модель LSTM с эмбеддингом, LSTM слоями и линейным классификатором.
- Реализация циклов обучения и оценки с ведением метрик и построением графиков.
- Использование `pipeline` из библиотеки Hugging Face для генерации текста трансформером distilgpt2 и оценки его качества.
- Подсчёт метрик ROUGE-1 и ROUGE-2 для оценки качества генерации.
- Сохранение подготовленных датасетов и весов обученной модели.

## Структура проекта
- `data_utils.py`: обработка текста, токенизация, подготовка датасета, вычисление ROUGE.
- `next_token_dataset.py`: класс PyTorch Dataset для подачи пар токенов.
- `lstm_model.py`: определение модели LSTM и метода генерации текста.
- `eval_lstm.py`: функции для обучения и оценки модели LSTM.
- `lstm_train.py`: скрипт для запуска подготовки данных, обучения и оценки модели.
- `eval_transformer_pipeline.py`: код для генерации и оценки текста трансформером distilgpt2.
- `data/`: папка с исходными и подготовленными CSV-файлами датасетов.
- `models/`: папка для сохранения весов обученной модели.
- `configs/`: (опционально) папка с YAML-конфигурациями проекта.

## Установка
1. Клонируйте репозиторий.
2. Установите зависимости.
3. При необходимости установите `tf-keras` для совместимости с некоторых сред.


## Как использовать
### Обработка данных и обучение модели
- Запустите `lstm_train.py` или выполните соответствующие ячейки в Jupyter Notebook для:
- загрузки и очистки исходных текстов (`data/tweets.txt`)
- подготовки и токенизации данных для обучения
- разбиения датасета на наборы train, val и test
- обучения модели LSTM с отслеживанием потерь
- сохранения весов обученной модели

### Оценка моделей
- Используйте `eval_lstm.py` для оценки LSTM на валидационной и тестовой выборках.
- Запустите `eval_transformer_pipeline.py` для генерации и оценки текста с помощью distilgpt2.
- Выводятся средние значения ROUGE для сравнения качества генераций.

## Замечания
- В проекте используется RuBERT токенизатор для русского языка, но архитектуру можно адаптировать под другие языки и токенизаторы.
- Использование трансформеров даёт сильный базовый уровень для автодополнения.
- В реализации предусмотрена обработка паддинга и усечения текста.
- Качество результатов зависит от параметров обучения и качества исходных данных.

## Обратная связь
Вопросы, предложения и участие в развитии проекта приветствуются через issues или контакты автора.


# text-autocomplete
